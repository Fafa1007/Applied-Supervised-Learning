# Logistic Regression With A Non-Linear Decision Boundary

Apply 10-fold cross-validation throughout to measure classification accuracy

## Modelling

You may specify the model and regularize (or not) in any way you wish, just be sure to clearly state your final model.

Vanilla Model

```{r}
# Vanilla Logistic Regression Model
log_mod <- glm(Revenue ~ ., family = binomial,data = train)
log_mod %>% 
  tidy() %>%
  kable(digits = 2, caption = 'Vanilla Logistic Regression Model')
```

Polynomial Logistic Regression Models (choose the variables to make 5th degree polynomials by looking at the most significant numerical variables from the vanilla model)

1.  Polynomial Logistic Model with all variables

```{r}
poly_log1 <- glm(Revenue ~ 
            Informational + I(Informational^2) + I(Informational^3) +I(Informational^4) + 
            ProductRelated_Duration + I(ProductRelated_Duration^2) + I(ProductRelated_Duration^3) + I(ProductRelated_Duration^4) +
            ExitRates + I(ExitRates^2) + I(ExitRates^3) + I(ExitRates^4) + 
            PageValues + I(PageValues^2) + I(PageValues^3) + I(PageValues^4) + .
            ,data = train, family = 'binomial')
poly_log1 %>% 
  tidy() %>%
  kable(digits = 2, caption = 'Polynomial logistic regression model fitted to the online shopping dataset using all the varibles')
```

2.  Polynomial Logistic Model with only the polynomial variables

```{r}
poly_log2 <- glm(Revenue ~ 
            Informational + I(Informational^2) + I(Informational^3) +I(Informational^4) + 
            ProductRelated_Duration + I(ProductRelated_Duration^2) + I(ProductRelated_Duration^3) + I(ProductRelated_Duration^4) +
            ExitRates + I(ExitRates^2) + I(ExitRates^3) + I(ExitRates^4) + 
            PageValues + I(PageValues^2) + I(PageValues^3) + I(PageValues^4) 
            ,data = train, family = 'binomial')
poly_log2 %>% 
  tidy() %>%
  kable(digits = 2, caption = 'Polynomial logistic regression model fitted to the online shopping dataset using only the polynomial variables')

```

------------------------------------------------------------------------

\newpage

## Inference/Interpretation

```{r}
# Coefficients
poly_log1 %>% 
  tidy() %>%
  kable(digits = 2, caption = 'Polynomial logistic regression model fitted to the online shopping dataset using all the varibles')
```

1.  **PageValues is the most significant predictor with strong non-linear effects**: The linear term for *PageValues* (3.31, p \< 0.00) has the highest positive coefficient, indicating that higher page values significantly increase the likelihood of purchase. However, the squared term (*I(PageValues\^2)*, -1.07, p \< 0.00) and higher-order polynomial terms reveal a non-linear relationship, suggesting diminishing returns at very high page values. This aligns with the study's focus on leveraging clickstream data to predict purchasing intent, emphasizing the importance of high-value page interactions.

2.  **ExitRates and BounceRates negatively impact purchasing intent**: Both *ExitRates* (-0.68, p = 0.01) and *BounceRates* (-0.60, p = 0.01) have significant negative coefficients, indicating that higher exit and bounce rates reduce the likelihood of purchase. While the polynomial terms for *ExitRates* are not statistically significant, the linear term underscores the importance of retaining visitors on the site to improve conversion rates, as highlighted in the study.

3.  **Temporal factors show strong seasonal effects**: Months like *November* (0.51, p = 0.01) have a positive coefficient, indicating higher purchasing intent during this period, likely due to holiday shopping. Conversely, *February* (-1.71, p = 0.03), *December* (-0.74, p \< 0.00), *March* (-0.72, p \< 0.00), and *May* (-0.77, p \< 0.00) show significant negative coefficients, reflecting lower shopping activity during these months. These findings align with the study's emphasis on using session data to capture temporal patterns in shopper behavior.

4.  **Visitor type and weekend visits influence purchasing intent**: *Returning_Visitor* (-0.54, p \< 0.00) has a significant negative coefficient, suggesting that returning visitors are less likely to purchase compared to new visitors. Additionally, *WeekendTRUE* (0.20, p = 0.03) has a positive coefficient, indicating that visits during weekends are associated with higher purchasing intent. These insights support the study's focus on combining visitor-type and temporal features to improve prediction accuracy.

------------------------------------------------------------------------

\newpage

## Model Evaluation

```{r}
library(MLmetrics)
library(caret)
library(knitr)
library(dplyr)
library(ROCR)

# Firstly, get predicted probabilities or predicted classe (gives the same conclusions) from the model
pred_probabilities <- predict(poly_log1,x_valid, type = "response")

# Secondly, create a confusion matrix
yhat <- ifelse(pred_probabilities >= 0.5,'Revenue', "No Revenue")
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 'Revenue', "No Revenue"))
cat("Confusion Matrix using Predicted Probabilities")
(confmat <- table(yhat, y, dnn = c('Predicted label', 'True label')))

# Thirdly, get the Accuracy, F1 Score, Precision, Recall, Specificity which we can calculate from the confusion matrix .... or us the caret package 
caretmat <- confusionMatrix(as.factor(yhat), as.factor(y), positive = 'Revenue')
caretmat 

Sensitivity <- caretmat$byClass["Sensitivity"]  # True Positive Rate (Recall)
Specificity <- caretmat$byClass["Specificity"]  # True Negative Rate
Precision <- caretmat$byClass["Precision"]      # Positive Predictive Value
F1_score <- caretmat$byClass["F1"]              # F1 Score
Accuracy <- caretmat$overall["Accuracy"]        # Accuracy
Missclassification_Rate <- mean(yhat != y)

# AUC (only works with binary data)
yhat <- ifelse(pred_probabilities >= 0.5, 1, 0)
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 1, 0))
pred_obj <- prediction(y, yhat)
ROC_AUC <- performance(pred_obj, measure = "auc")@y.values[[1]]

# Lastly, put them all into a table
combined <- cbind(Sensitivity, Specificity, Precision, F1_score,Accuracy, Missclassification_Rate, ROC_AUC)
rownames(combined) <- c("Polynomial Logistic Regression")
kable(combined)

compar[2,] <- combined
```

------------------------------------------------------------------------

\newpage

## Optimizing F1 Score

------------------------------------------------------------------------

\newpage

## Prediction
