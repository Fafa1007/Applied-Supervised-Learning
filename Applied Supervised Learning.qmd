# A classification problem– Predicting online shoppers’ intention

The goal of this exercise is to predict whether or not online shoppers will finalize a transaction, based on data gathered about their browsing session. Therefore, the target variable Revenue– is binary. The data were first presented and analysed by Sakar et al. (2018); descriptions of all 17 features can be found in this paper, although some variables have been removed and others adjusted in order to simplify the analysis a bit. Several publications have subsequently analysed these data, including Mostafa et al. (2024) and Swetha et al. (2024). The aim is to recreate some of their results. Note, however, that you will not be graded on the accuracy of the results, but rather by the procedure followed and the clarity in communication and presentation thereof.

The dataset has been split into a training set and validation set (i.e. online_shopping_train.csv and online_shopping_valid.csv). These files must be read into R as is, i.e. the spreadsheets may not be edited at all.

Provide a brief introduction to the report; a reader should be able to comprehend the task at hand without having seen this set of instructions. Although an exploration/description of the features is not required, a brief section on this may be included. If you do, your discussion should focus only on aspects that pertain to this exercise

```{r}
train <- read.csv("_raw_data/online_shopping_train.csv")
test <- read.csv("_raw_data/online_shopping_testing.csv")
valid <- read.csv("_raw_data/online_shopping_valid.csv")
head(train)
```

First convert categorical variables into factor type, stating for which features this was done.

```{r}
factor_cols <- c("Month", "OperatingSystems", "Browser", "VisitorType", "Weekend", "Revenue")

scale_cols <- c("Administrative","Administrative_Duration", "Informational", "Informational_Duration","ProductRelated","SpecialDay", "ProductRelated_Duration","BounceRates", "ExitRates", "PageValues")

train[factor_cols] <- lapply(train[factor_cols], factor)
train[scale_cols] <- lapply(train[scale_cols], scale)
y_train <- train["Revenue"]
x_train <- train[, -16]
head(train)

valid[factor_cols] <- lapply(valid[factor_cols], factor)
valid[scale_cols] <- lapply(valid[scale_cols], scale)
y_valid <- valid["Revenue"]
x_valid <- valid[,-16]

test[head(factor_cols,-1)] <- lapply(test[head(factor_cols,-1)], factor)
test[scale_cols] <- lapply(test[scale_cols], scale)
```

------------------------------------------------------------------------

\newpage

## Evaluation Metrics Of All The Models

```{r}
library(ggplot2)
# Combine all evaluation metrics
compar <- matrix(0, ncol=7, nrow=6)

# FIRST, NOW RUN EVERY MODEL EVALUATION PARTS FIRST TO ADD THE EVALUATION METRICS TO THE COMPAR MATRIX

```

```{r}
# AFTER RUNNING EVERY MODELS EVALUATION SECTIONS
# NOW SHOULD HAVE ALL THE METERICS FOR EVERY MODEL
colnames(compar) <- c("Sensitivity", "Specificity", "Precision", "F1_score","Accuracy", "Missclassification_Rate", "ROC_AUC")
rownames(compar) <- c("Logistic Regression with Elastic Regularisation", "Polynomial Logistic Regression","K-Nearest-Neighbours","Classification Tree", "Tuned Random Forest",  "Gradient Boosted Model")

compar
```

```{R}
# SECONDLY, PLOT OUT THE BAR GRAPH TO COMPARE THE METERICS FOR EACH MODEL
df <- data.frame(compar)
df$Model <- rownames(df)  # Add model names
df_long <- pivot_longer(df, cols = -Model, names_to = "Metric", values_to = "Value")
ggplot(df_long, aes(x = Metric, y = Value, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Model Performance Comparison",
       x = "Performance Metric",
       y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels
```
