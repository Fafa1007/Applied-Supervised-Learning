# GBM Tree Model

#### Set-Up

```{r}
library(class)
library(ggplot2)
library(caret)
library(gbm)
library(xgboost)
library(ROCR)
library(dplyr)
library(tidyverse)
library(knitr)
library(doParallel)
library(pROC)
library(gridExtra)
library(grid)
library(pdp)



train <- read.csv("online_shopping_train.csv")
test <- read.csv("online_shopping_testing.csv")
valid <- read.csv("online_shopping_valid.csv")

head(train)

factor_cols <- c("Month", "OperatingSystems", "Browser", "VisitorType", "Weekend", "Revenue")

scale_cols <- c("Administrative","Administrative_Duration", "Informational", "Informational_Duration","ProductRelated","SpecialDay", "ProductRelated_Duration","BounceRates", "ExitRates", "PageValues")

train[factor_cols] <- lapply(train[factor_cols], factor)
train[scale_cols] <- lapply(train[scale_cols], scale)
y_train <- train["Revenue"]
x_train <- train[, -16]

valid[factor_cols] <- lapply(valid[factor_cols], factor)
valid[scale_cols] <- lapply(valid[scale_cols], scale)
y_valid <- valid["Revenue"]
x_valid <- valid[,-16]

test[head(factor_cols,-1)] <- lapply(test[head(factor_cols,-1)], factor)
test[scale_cols] <- lapply(test[scale_cols], scale)
```

Apply 10-fold cross-validation throughout to measure classification accuracy

## Modelling

```{r}
#| warning: false

# Detect available cores
num_cores <- detectCores() - 1  # Leave 1 core free for system processes

# Register the parallel backend
#cl <- makeCluster(num_cores)  
#registerDoParallel(cl)

#set.seed(4026)

#ctrl <- trainControl(method = 'cv', number = 10, verboseIter = T, allowParallel = TRUE)

#calif_gbm_grid <- expand.grid(n.trees = c(1000, 10000, 30000),
#                              interaction.depth = c(2, 5, 8),
#                              shrinkage = c(0.01, 0.005),
#                              n.minobsinnode = 10)
#
#calif_gbm_gridsearch <- train(Revenue ~ ., data = train,
#                              method = 'gbm',
#                              distribution = 'bernoulli',
#                              trControl = ctrl,
#                              verbose = T,
#                              tuneGrid = calif_gbm_grid)
#stopCluster(cl)
#registerDoSEQ()

if (!dir.exists("data")) dir.create("data")  # Create 'data' folder if missing
# save(calif_gbm_gridsearch, file = 'data/gbm_calif_50k.Rdata')
load('data/gbm_calif_50k.Rdata')

plot(calif_gbm_gridsearch)

train$Revenue <- as.numeric(train$Revenue) - 1

#calif_fe_gbm <-   gbm(Revenue ~ ., data = train, 
#                      distribution = "bernoulli", 
#                      n.trees = calif_gbm_gridsearch$bestTune$n.trees, 
#                      interaction.depth = calif_gbm_gridsearch$bestTune$interaction.depth, 
#                      shrinkage = calif_gbm_gridsearch$bestTune$shrinkage, 
#                      bag.fraction = 1, 
#                      cv.folds = 10,  #built-in CV
#                      n.cores = 9,   #which can be parallelised
#                      verbose = T)

#save(calif_fe_gbm, file = 'data/gbm_calif_100k.Rdata')
load('data/gbm_calif_100k.Rdata')

```

------------------------------------------------------------------------

\newpage

## Model Evaluation (ques 1 b)

```{r}
prob_pred_gbm <- predict(calif_fe_gbm, valid[, -16], type = "response", n.trees = calif_fe_gbm$bestTune$n.trees)
yhat_gbm <- ifelse(prob_pred_gbm >= 0.5,'Revenue', "No Revenue")
y_gbm <- matrix(ifelse(as.numeric(unlist(valid[,16]))==2, 'Revenue', "No Revenue"))
cat("Confusion Matrix using Predicted Probabilities")
(confmat <- table(yhat_gbm, y_gbm, dnn = c('Predicted label', 'True label')))

caretmat <- confusionMatrix(as.factor(yhat_gbm), as.factor(y_gbm), positive = 'Revenue')
caretmat 

Sensitivity <- caretmat$byClass["Sensitivity"]  # True Positive Rate (Recall)
Specificity <- caretmat$byClass["Specificity"]  # True Negative Rate
Precision <- caretmat$byClass["Precision"]      # Positive Predictive Value
F1_score <- caretmat$byClass["F1"]              # F1 Score
Accuracy <- caretmat$overall["Accuracy"]        # Accuracy
Missclassification_Rate <- mean(yhat_gbm != y_gbm)

# AUC (only works with binary data)
y_gbm <- matrix(ifelse(as.numeric(unlist(valid[,16]))==2, 1, 0))
pred_obj_gbm <- prediction(as.numeric(prob_pred_gbm), as.numeric(y_gbm))
ROC_AUC <- performance(pred_obj_gbm, measure = "auc")@y.values[[1]]

combined <- cbind(Sensitivity, Specificity, Precision, F1_score,Accuracy, Missclassification_Rate, ROC_AUC)
rownames(combined) <- c("Polynomial Logistic Regression")
kable(combined)

compar[6,] <- combined
```

------------------------------------------------------------------------

\newpage

## Inference/Interpretation

```{r}
# Variable Importance Plots
plot.new()
d <- gbm.perf(calif_fe_gbm)
legend('topright', c('CV error', 'Training error'), col = c('green', 'black'), lty = 1)


par(mar=c(5,6,4,1) + 0.1)
calif_gbm_varimp <- summary(calif_fe_gbm, n.trees = d, las = 1, xlim = c(0, 50))

# Partial Dependency Plots

# Get variable importance from the GBM model
var_importance <- summary(calif_fe_gbm, plotit = FALSE)

# Select top N variables (e.g., top 4)
top_vars <- var_importance$var[1:4]

library(gridExtra)
library(grid)

ylims <- c(-5,2)
p1 <- plot.gbm(calif_fe_gbm, 'PageValues', d, ylim = ylims, ylab = '')
p2 <- plot.gbm(calif_fe_gbm, 'Month', d, ylim = ylims, ylab = '')
p3 <- plot.gbm(calif_fe_gbm, 'BounceRates', d, ylim = ylims, ylab = '')
p4 <- plot.gbm(calif_fe_gbm, 'ProductRelated_Duration', d, ylim = ylims, ylab = '')

grid.arrange(p1, p2, p3, p4, ncol = 2)
grid.text('Revenue', x = 0, vjust = 1, rot = 90)
```

------------------------------------------------------------------------

## Optimising F1 Score

```{r}
#| warning: false
#| message: false

# Finding Maximum F1 Score and Corresponding Tau
prob_pred_gbm <- predict(calif_fe_gbm, valid[, -16], type = "response", n.trees = calif_fe_gbm$bestTune$n.trees)

F1_score_vec <- vector()
tau <- vector()
seq_i <- seq(min(prob_pred_gbm) + 0.0001 ,max(prob_pred_gbm) - 0.0001,length = 1000)
index <- 1

for (i in seq_i) {
  yhat_gbm <- ifelse(prob_pred_gbm >= i,'Revenue', "No Revenue")
  y_gbm <- matrix(ifelse(as.numeric(unlist(valid[,16]))==2, 'Revenue', "No Revenue"))
  confmat <- table(yhat_gbm, y_gbm, dnn = c('Predicted label', 'True label'))

  caretmat <- confusionMatrix(as.factor(yhat_gbm), as.factor(y_gbm), positive = 'Revenue')
   
  F1_score_vec[index] <- caretmat$byClass["F1"]
  tau[index] <- i
  index <- index + 1
}

df <- data.frame(x = tau, y = F1_score_vec)
mf <- max(F1_score_vec)
max_F1_tau <- df$x[df$y == mf]

# Plotting F Score Account Tau
df <- data.frame(x = tau, y = F1_score_vec)

f1_t_6 <- ggplot() + geom_line(data = df, aes(x = x, y = y)) + geom_vline(xintercept = max_F1_tau, color = "red", linetype = "dashed") + theme_minimal() + labs(x = "Tau", y = "F1 Score", title = "F1 Score Against Different Desician Rule Thresholds (Tau) for a GBM Model")
f1_t_6

# ROC Curve Plot
pred_gbm <- prediction(as.numeric(prob_pred_gbm), as.numeric(valid[,16]))
perf_gbm  <- performance(pred_gbm, 'tpr', 'fpr')
plot.new()        # Start a new plot (if needed)
plot(perf_gbm, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)

yhat_gbm <- ifelse(prob_pred_gbm >= max_F1_tau,'Revenue', "No Revenue")
y_gbm <- matrix(ifelse(as.numeric(unlist(valid[,16]))==2, 'Revenue', "No Revenue"))
cat("Confusion Matrix using Predicted Probabilities")
(confmat <- table(yhat_gbm, y_gbm, dnn = c('Predicted label', 'True label')))

caretmat_gbm <- confusionMatrix(as.factor(yhat_gbm), as.factor(y_gbm), positive = 'Revenue')

TPR <- caretmat_gbm$byClass["Sensitivity"]  # True Positive Rate (Recall)
FPR <- 1 - caretmat_gbm$byClass["Specificity"]

points(
  x = FPR, 
  y = TPR,
  pch = 19,          # Solid circle point
  col = "red",       # Color of the point
  cex = 1          # Point size
)

text(
  x = FPR + 0.15,    # Offset text slightly to the right
  y = TPR - 0.08, 
  labels = paste0("Threshold: ", round(max_F1_tau, 3)), 
  col = "black"
)

text(
  x = FPR + 0.15,
  y = TPR - 0.16,  # Second label: slightly below the point
  labels = paste("F1 Score:", round(mf, 3)),  # Example metric
  col = "black"
)



```

------------------------------------------------------------------------

\newpage

## Prediction
