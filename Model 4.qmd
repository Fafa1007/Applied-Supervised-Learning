# Classification Tree

Apply 10-fold cross-validation throughout to measure classification accuracy

## Modelling

Finding and motivating our choice of the tree size we wish to prune our over fitted tree towards.

```{r}
library(tree)

set.seed(4026)

# First, grow an overfitted tree 
tree_overfit <- tree(Revenue ~ ., data = train,
                        control = tree.control(nobs = nrow(na.omit(train)),
                                               mindev = 0.005))

# Second, 10 fold CV to find the best number of tree nodes to prune
tree_cv <- cv.tree(tree_overfit, FUN = prune.misclass, K = 10) 
#Use classification error rate for pruning
```

```{r}
# Thirdly, make the CV plot to visually observe the best number of tree nodes to prune with the lowest cross validation error
plot(tree_cv$size, tree_cv$dev, type = 'o',
     pch = 16, col = 'navy', lwd = 2,
     xlab = 'Number of terminal nodes', ylab='CV error')

tree_cv$k[1] <- 0 #Don't want no -Inf
alpha <- round(tree_cv$k,1)
axis(3, at = tree_cv$size, lab = alpha, cex.axis = 0.8)
mtext(expression(alpha), 3, line = 2.5, cex = 1.2)
axis(side = 1, at = 1:max(tree_cv$size))

# T is the hyper parameter for the number of terminal nodes
T <- tree_cv$size[which.min(tree_cv$dev)] #The minimum CV Error
abline(v = T, lty = 2, lwd = 2, col = 'red')
```

Pruned Tree Model

```{r}
# Lastly, here is the final pruned Tree Model
pruned_tree <- prune.misclass(tree_overfit, best = T)

save(pruned_tree, file = 'R Data/Pruned Classification Tree Model.Rdata')
```

------------------------------------------------------------------------

\newpage

## Model Evaluation

```{r}
library(MLmetrics)
library(caret)
library(knitr)
library(dplyr)
library(ROCR)

# Firstly, get predicted probabilities or predicted classe (gives the same conclusions) from the regularised logistic model
pred_probabilities <- predict(pruned_tree,x_valid, type = "vector")[, "1"]

# Secondly, create a confusion matrix
yhat <- ifelse(pred_class >=0.5,'Revenue', "No Revenue")
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 'Revenue', "No Revenue"))
cat("Confusion Matrix using Predicted Probabilities")
(confmat <- table(yhat, y, dnn = c('Predicted label', 'True label')))

# Thirdly, get the Accuracy, F1 Score, Precision, Recall, Specificity which we can calculate from the confusion matrix .... or us the caret package 
caretmat <- confusionMatrix(as.factor(yhat), as.factor(y), positive = 'Revenue')
caretmat 

Sensitivity <- caretmat$byClass["Sensitivity"]  # True Positive Rate (Recall)
Specificity <- caretmat$byClass["Specificity"]  # True Negative Rate
Precision <- caretmat$byClass["Precision"]      # Positive Predictive Value
F1_score <- caretmat$byClass["F1"]              # F1 Score
Accuracy <- caretmat$overall["Accuracy"]        # Accuracy
Missclassification_Rate <- mean(yhat != y)

# AUC (only works with binary data)
yhat <- ifelse(pred_class == 1, 1, 0)
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 1, 0))
pred_obj <- prediction(y, yhat)
ROC_AUC <- performance(pred_obj, measure = "auc")@y.values[[1]]

# Lastly, put them all into a table
combined <- cbind(Sensitivity, Specificity, Precision, F1_score,Accuracy, Missclassification_Rate, ROC_AUC)
rownames(combined) <- c("Classification Tree")
kable(combined)

compar[4,] <- combined
```

------------------------------------------------------------------------

\newpage

## Inference/Interpretation

```{r}
# Pruned Classification Tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)
pruned_tree
```

1.  **PageValues is the primary driver of purchasing intent**: The root node splits on *PageValues*, with a threshold of -0.262927. Visitors with lower *PageValues* (node 2, 78.76% of the data) have a low likelihood of purchasing (4.16% probability), while those with higher *PageValues* (node 3, 21.24% of the data) show a significantly higher likelihood of purchasing (56.74% probability). This aligns with the study's emphasis on the importance of high-value page interactions in predicting purchasing intent.

2.  **Seasonal effects are evident in the data**: The tree further splits on *Month*, revealing distinct seasonal patterns. For example, in node 4 (February, March, May), all visitors have a 0% probability of purchasing, indicating low shopping activity during these months. In contrast, node 11 (July, November, September) shows an 11.12% probability of purchasing, with higher activity during these months. This supports the study's findings on the influence of temporal factors on shopper behavior.

3.  **ProductRelated_Duration and BounceRates refine predictions**: The tree uses *ProductRelated_Duration* and *BounceRates* to further refine predictions. For instance, in node 23, visitors with higher *ProductRelated_Duration* (above -0.0118301) have an 18.93% probability of purchasing, compared to 7.18% for those with lower durations (node 22). Similarly, in node 6, visitors with lower *BounceRates* (below -0.451897) have a 74.12% probability of purchasing, highlighting the negative impact of high bounce rates on conversion rates, as noted in the study.

4.  **Combining features improves prediction accuracy**: The tree demonstrates the value of combining multiple features to improve prediction accuracy. For example, in node 15 (February, March, November), the probability of purchasing increases to 56.99% when combined with higher *PageValues* and moderate *BounceRates*. This aligns with the study's approach of leveraging both clickstream and session-based features to enhance the system's success rate.

------------------------------------------------------------------------

\newpage

## Optimizing F1 Score

------------------------------------------------------------------------

\newpage

## Prediction
