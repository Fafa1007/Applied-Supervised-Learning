# Logistic Regression With A Linear Decision Boundary (Elastic Regularisation).

Apply 10-fold cross-validation throughout to measure classification accuracy

## Modelling

Vanilla Logistic Regression Model

```{r}
library(tidyverse)
library(knitr)
library(broom)

set.seed(4026)

# Vanilla logistic regression model to the entire dataset
log_mod <- glm(Revenue ~ ., family = binomial,data = train)
log_mod %>% 
  tidy() %>%
  kable(digits = 2, caption = 'Vanilla logistic regression model')
```

Finding and motivating our choice of α and λ hyper parameters for the Elastic-Net Regularisation.

```{r}
# Elastic Net
library(glmnet)
library(plotmo)
library(glmnetUtils)

set.seed(4026)

# Firstly, prepare the data for elastic-net regularization by creating dummy variables for factor columns
train_dummies <- makeX(x_train)

# Secondly, perform 10 fold cross-validation to find the optimal alpha and lambda hyperparameters
elasticnet_cv <- cva.glmnet(train_dummies, as.numeric(unlist(y_train)), alpha = seq(0, 1, 0.1), nfolds = 10)

# Thirdly, plot the cross-validation error against lambda for different fixed values of alpha
plot(elasticnet_cv, main ="Cross Validation Error as lambda increases for 
different fixed values of alpha")

# Fourthly, extract the alpha and lambda hyperparameters that give the lowest cross-validation error
alphas <- elasticnet_cv$alpha 
cv_mses <- sapply(elasticnet_cv$modlist,
  function(mod) min(mod$cvm) 
  )

lowest_mse <- round(min(cv_mses),5)
best_alpha <- alphas[which.min(cv_mses)]
best_lambda <- round(elasticnet_cv$modlist[[which.min(cv_mses)]]$lambda.min,6)

print(paste("The lowest CV MSE is", lowest_mse))
print(paste("The Alpha corresponding to this minumum is", best_alpha))
print(paste("The Lamda acorresponding to this minumum is", best_lambda))

# Lastly, plot the lowest MSE for each alpha and highlight the best alpha 
plot(alphas, cv_mses, 'b', lwd = 2, pch = 16, col = 'navy', xlab = expression(alpha), ylab = 'CV MSE')
abline(v = best_alpha, lty = 3, col = 'red')
```

Finally our Logistic Regression Model with Elastic-Net Regularization

```{r}
library(glmnet)

# Fit a logistic regression model with elastic-net regularization using the best alpha and lambda
log_elas <- glmnet(train_dummies, as.numeric(unlist(y_train)), family = "binomial", alpha = best_alpha, lambda = best_lambda, standardize = T)

save(log_elas, file = 'R Data/Logistic Regression Elastic Regularisation Model.Rdata')
```

------------------------------------------------------------------------

\newpage

## Model Evaluation decision threshold of 0.5

```{r}
library(MLmetrics)
library(caret)
library(knitr)
library(dplyr)
library(ROCR)

# Firstly, get predicted probabilities or predicted classe (gives the same conclusions) from model
x_valid_dummies <- makeX(x_valid)
pred_probabilities <- predict(log_elas, newx = as.matrix(x_valid_dummies), type = "response")

# Secondly, create a confusion matrix
yhat <- ifelse(pred_probabilities >= 0.5, 'Revenue', 'No Revenue')
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 'Revenue', "No Revenue"))
cat("Confusion Matrix using Predicted Probabilities")
(confmat <- table(yhat, y, dnn = c('Predicted label', 'True label')))

# Thirdly, get the Accuracy, F1 Score, Precision, Recall, Specificity which we can calculate from the confusion matrix .... or us the caret package 
caretmat <- confusionMatrix(as.factor(yhat), as.factor(y), positive = 'Revenue')
caretmat 

Sensitivity <- caretmat$byClass["Sensitivity"]  # True Positive Rate (Recall)
Specificity <- caretmat$byClass["Specificity"]  # True Negative Rate
Precision <- caretmat$byClass["Precision"]      # Positive Predictive Value
F1_score <- caretmat$byClass["F1"]              # F1 Score
Accuracy <- caretmat$overall["Accuracy"]        # Accuracy
Missclassification_Rate <- mean(yhat != y)

# AUC need the values to be binary
yhat <- ifelse(pred_probabilities >= 0.5, 1, 0)
y <- matrix(ifelse(as.numeric(unlist(y_valid))==2, 1, 0))
pred_obj <- prediction(y, yhat)
ROC_AUC <- performance(pred_obj, measure = "auc")@y.values[[1]]

# Lastly, put them all into a table
combined <- cbind(Sensitivity, Specificity, Precision, F1_score,Accuracy, Missclassification_Rate, ROC_AUC)
rownames(combined) <- c("Logistic Regression with Elastic Regularisation")
kable(combined)

compar[1,] <- combined
```

------------------------------------------------------------------------

\newpage

## Inference/Interpretation

```{r}
# Coefficients
coef(log_elas)
```

1.  **PageValues and ExitRates are the most influential predictors**: The coefficient for *PageValues* (1.4418) is the highest positive value, indicating that visitors who view high-value pages are significantly more likely to have purchasing intent. Conversely, *ExitRates* has a strong negative coefficient (-0.7517), suggesting that higher exit rates are strongly associated with a lower likelihood of purchase, aligning with the study's focus on predicting shopping intent and abandonment.

2.  **Duration-based features show mixed effects**: While *ProductRelated_Duration* (0.1110) has a positive coefficient, indicating that longer time spent on product-related pages increases purchase intent, *Administrative_Duration* (-0.0217) has a negative coefficient, implying that more time on administrative pages may reduce intent. This highlights the importance of differentiating between page types in predicting shopper behavior.

3.  **Seasonal and visitor-type effects are significant**: Months like *July* (0.5088) and *November* (0.8363) have positive coefficients, suggesting higher purchase intent during these periods, while *February* (-1.1118) shows a strong negative effect. Additionally, *New_Visitor* (0.2957) has a positive coefficient, indicating that new visitors are more likely to purchase compared to other visitor types, which aligns with the study's emphasis on session and user information.

4.  **Technical factors like browser and operating systems have nuanced impacts**: Certain browsers, such as *Browser5* (0.3971) and *Browser8* (0.4644), are positively associated with purchase intent, while *Browser3* (-0.3611) has a negative effect. Similarly, some operating systems (*OperatingSystems3* and *4*) show negative coefficients, suggesting that technical configurations can influence shopper behavior, though their impact is less pronounced compared to behavioral metrics like *PageValues* and *ExitRates*.

------------------------------------------------------------------------


\newpage

## Optimizing F1 Score

```{r}
auc_cv <- cv.glmnet(x_train_dummies, y_train, family = 'binomial', type.measure = 'auc', keep = T)
all_rocs <- roc.glmnet(auc_cv$fit.preval, newy = y_train) #67 different curves!

best_roc <- auc_cv$index['min', ] #Also labeled min, even though here it's a max :|

round(coef(auc_cv, s = 'lambda.min'), 3)
```

------------------------------------------------------------------------

\newpage

## Prediction
